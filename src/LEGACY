"""
FROM analysis_grid_cell_dissection
CLASS: Blob
"""

    def get_gaussian_probabilities(self):

        #P(X) = exp(-(X-m)^2/(2s^2))/(s sqrt(2*pi))
        pass

    def detect_fill(self, prob_array):
        """This function is not in use and should not be called"""

        return None

        self.filter_array = np.zeros(self.filter_array.shape)
        still_blob = True
        seed = prob_array.argmax()
        self.filter_array[seed] = True

        while still_blob:

            pass

        self.filter_array[seed] = False


"""
FROM analysis_grid_cell
CLASS: Grid_Cell
"""
    def detach_analysis(self, blob=True, background=True, cell=True):
        """detach_analysis disconnects the analysis modules specified
        from the Grid_Cell instance.

        Function has three optional boolean arguments:

        @blob           Detaches blob analysis (default)
                        This also detaches background

        @background     Detaches background analysis (default)

        @cell           Detaches cell analysis (default)"""

        if blob:

            self._analysis_items['blob'] = None
            self._analysis_items['background'] = None

        if background:

            self._analysis_items['background'] = None

        if cell:

            self._analysis_items['cell'] = None

"""
FROM analysis_grid_cell
CLASS: N/A
"""

def crop(A, rect):
    """ Crop numpy matrix/array A with rect = (x,y,width,height) where (x,y)
    is the topLeft corner of the rect """

    return A[rect[1]: (rect[3] + rect[1]), rect[0]: (rect[2] + rect[0])]


def compute_rect(center, rectSize):
    """ Typically you call this function with rectSize = interDist which is
    the default grid-rect size, but it might be the case that the size is
    set to smaller manually by invoking method setRectSize in class GridArray.

    rectSize can also be a tuple (width,height)

    for even, integer valued rectSize, the topLeft corner of the resulting
    rectangle will be center-rectSize/2 , which results in a rect
    "biased upwards to the left"

    if rectSize is empty or has negative elements, an ndarray
    with -1 elements is returned"""

    center = np.asarray(center)
    #print rectSize
    if np.isscalar(rectSize):

        rectSize = np.asarray([rectSize, rectSize])

    else:

        rectSize = np.asarray(rectSize)

    if (rectSize < 0).any() or rectSize.size == 0:

        return np.asarray([-1, -1, -1, -1])

    topLeft = center - rectSize / 2.0

    return np.asarray(tuple(topLeft) + tuple(rectSize))

#
# SPREADSHEET COMPATIBILITY FUNCTIONS
#


def ystring(ycoor):
    """'ystring' produces a string representation for the ycoor (integer >=1)
    that corresponds to Excels column annotation.
    1 (first column) => 'A'
    2                => 'B'
    ...
    26               => 'Z'
    27               => 'AA'
    28               => 'AB' (etc

    Note that this is NOT the typical representation in another base/alphabet,
    since in that case 'A' should correspond to 0, 'B' to 1, and 'Z' to 25, and
    'BA' to 26 since these would be short-hand to 'AAA' <=> 0, 'AAB' <=> 1,
    'AAZ'<=> 25 and 'ABA' to 26.
    Of course this could be offset:ed with +1, but it does not change
    the fact that it is another algorithm for columns/rows >=27"""

    if ycoor < 27:

        return chr(65 + ycoor - 1)

    else:

        y = ycoor - 1
        next = y / 26
        rest = y % 26

        return ystring(next) + chr(65 + rest)


def create_id_tag(xcoor, ycoor, nrCols, nrRows):

    #x = xcoor-1;
    nrDigits = math.floor(math.log10(nrCols) + 1)
    template = '%0' + ('%d' % (nrDigits)) + 'd'

    return ystring(ycoor) + (template % (xcoor))



"""
FROM: analysis_grid_array_dissection
CLASS: Grid_Analysis
"""

    def get_spikes(self, dimension, im=None, visual=False, verbose=False,
             use_otsu=True, median_coeff=0.99, manual_threshold=None):
        """
        get_spikes returns a spike list for a dimension of an image array

        The function takes the following arguments:

        @dimension  The dimension to be analysed (0 or 1)

        @im         An image numpy array, if left out previously loaded
                    image will be used

        @visual     Plot the results (only possible when running
                    the script from prompt)

        @verbose   Do a whole lot of print out of everything to
                    debug what goes wrong.

        @use_otsu   Using the Otsu algorithm to set the threshold used in
                    spike detection (default True). If Otsu is not used,
                    the median coefficient is used.

        @median_coeff   A float that is multiplied to the median of the
                        1D flattned image to get a threshold if otsu is not
                        used.
        """

        if im == None:

            im = self.im

        im_1D = im.mean(axis=dimension)

        if use_otsu:

            self.histogram.re_hist(im_1D)
            self.threshold = hist.otsu(histogram = self.histogram)

        elif manual_threshold:

            self.threshold = manual_threshold

        else:

            if median_coeff is None:

                median_coeff = 0.99

            self.threshold = np.median(im_1D) * median_coeff

        im_1D2 = (im_1D < self.threshold).astype(int)
        if visual:
            Y = im_1D2 * 100
            plt.plot(np.arange(len(im_1D)), im_1D, 'b-')
            plt.plot(np.arange(len(im_1D2)), Y, 'g-')
            #print self.threshold, median_coeff
            plt.axhline(y=self.threshold, color='r')
            plt.axhline(y=np.median(im_1D), color='g')

        #kernel = [-1,1]
        #spikes = np.convolve(im_1D, kernel, 'same')

        spikes_toggle_up = []
        spikes_toggle_down = []

        spikes_toggle = False

        for i in xrange(len(im_1D2)):

            if im_1D2[i] and not spikes_toggle:

                spikes_toggle = True
                spikes_toggle_up.append(i)

            elif not im_1D2[i]:

                if spikes_toggle == True:
                    spikes_toggle_down.append(i)

                spikes_toggle = False

        if len(spikes_toggle_down) != len(spikes_toggle_up):

            spikes_toggle_up = spikes_toggle_up[: len(spikes_toggle_down)]

        self.logger.debug("GRID CELL get_spikes, %d long %d downs %d ups." % \
            (len(im_1D2), len(spikes_toggle_down), len(spikes_toggle_up)))

        stt = (np.array(spikes_toggle_up) + np.array(spikes_toggle_down)) / 2

        if visual:

            Y = np.ones(len(stt)) * 80

            plt.plot(stt, Y, 'b.')
            plt.show()

        spike_f = stt[1:] - stt[: -1]

        return stt[1:], spike_f


"""
FROM: analysis_grid_array_dissection
CLASS: Grid_Analysis
"""

    def get_analysis(self, im, history=[]):
        """
        get_analysis is a convenience function for get_spikes and
        get_signal_position_and_frequency functions run on both
        dimensions of the image.

        (This function sets the self.im for get_spikes.)

        The function takes the following arguments:

        @im         An array / the image

        @pinning_matrix  A list/tuple/array where first position is
                        the number of rows to be detected and second
                        is the number of columns to be detected.

        @use_otsu   Causes thresholding to be done by Otsu
                    algorithm (Default)

        @median_coeff       Coefficient to threshold from the
                            median when not using Otsu.

        @verbose   If a lot of things should be printed out

        @visual     If visual information should be presented.

        @history    A history of the top-left positions selected
                    for the particular format for the particular plate

        The function returns two arrays, one per dimension, of the
        positions of the spikes and a quality index
        """


        self.im = im
        positions = [None, None]
        measures = [None, None]
        best_fit_frequency = [None, None]
        best_fit_positions = [None, None]
        adjusted_by_history = False

        R = 0

        if history is not None and len(history) > 0:

            history_rc = (np.array([h[1][0] for h in history]).mean(),
                np.array([h[1][1] for h in history]).mean())

            history_f = (np.array([h[2][0] for h in history]).mean(),
                np.array([h[2][1] for h in history]).mean())

        else:

            history_rc = None
            history_f = None

        """
        fig = plt.figure(10)
        fig.add_subplot(2,2,1).imshow(im, cmap=plt.cm.Greys)
        fig.add_subplot(2,2,2).plot(im.mean(0))
        t = hist.otsu(hist.Histogram(im.mean(0)))
        fig.gca().plot((0, im.shape[1]),(t, t))
        fig.gca().set_title("Dim 0 ({0})".format(pinning_matrix[dim_order[0]]))
        fig.add_subplot(2,2,3).plot(im.mean(1))
        t = hist.otsu(hist.Histogram(im.mean(1)))
        fig.gca().plot((0, im.shape[0]),(t, t))
        fig.gca().set_title("Dim 1 ({0})".format(pinning_matrix[dim_order[1]]))
        fig.show() 
        raw_input("Im {0}, Pin {1}, Order {2}".format(im.shape,
                pinning_matrix, dim_order))
        """

        #Obtaining current values by pinning grid dimension order

        np.save("_grid_im.npy", im)

        for dim in xrange(2):

            positions[dim], measures[dim] = \
                    self._get_new_spikes(
                    self.dim_order[dim]-1,
                    im=im)

            """
            positions[dim], measures[dim] = \
                    self.get_spikes(
                    self.dim_order[dim]-1,
                    im=im, visual=self.visual, verbose=self.verbose,
                    use_otsu=self.use_otsu, median_coeff=self.median_coeff,
                    manual_threshold=self.manual_threshold)
            """

            self.logger.info(
                "GRID ARRAY, Peak positions %sth dimension:\n%s" %\
                (str(dim), str(positions[dim])))

            best_fit_frequency[dim] = r_signal.get_signal_frequency(
                positions[dim])

            if best_fit_frequency[dim] is not None \
                                and history_f is not None:

                if abs(best_fit_frequency[dim] /\
                            float(history_f[dim]) - 1) > 0.1:

                    self.logger.warning(
                            ('GRID ARRAY, frequency abnormality for ' +\
                            'dimension {0} (Current {1}, Expected {2}'.format(
                            dim, best_fit_frequency[dim],
                            history_f)))

                    adjusted_by_history = True
                    best_fit_frequency[dim] = history_f[dim]

            best_fit_positions[dim] = r_signal.get_true_signal(
                im.shape[self.dim_order[dim]], self.pinning_matrix[dim],
                positions[dim],
                frequency=best_fit_frequency[dim],
                offset_buffer_fraction=0.5)

            if best_fit_positions[dim] is not None and \
                                        history_rc is not None:

                goodness_of_signal = r_signal.get_position_of_spike(
                    best_fit_positions[dim][0], history_rc[dim],
                    history_f[dim])

                if abs(goodness_of_signal) > 0.2:

                    self.logger.warning(("GRID ARRAY, dubious pinning " + \
                        "position for  dimension {0} (Current signal " + \
                        "start {1}, Expected {2} (error: {3}).".format(
                        dim, best_fit_positions[dim][0],
                        history_rc[dim], goodness_of_signal)))

                    adjusted_by_history = True

                    new_fit = r_signal.move_signal(
                        list(best_fit_positions[dim]),
                        [-1 * round(goodness_of_signal)], freq_offset=0)

                    if new_fit is not None:

                        self.logger.warning(
                            "GRID ARRAY, remapped signal for " +\
                            "dimension {0} , new signal:\n{1}".format(
                            dim, list(new_fit)))

                        best_fit_positions[dim] = new_fit[0]

            self.logger.info("GRID ARRAY, Best fit:\n" +\
                "* Elements: " + str(self.pinning_matrix[dim]) +\
                "\n* Positions:\n" + str(best_fit_positions[dim]))

            #DEBUGHACK
            #visual = True
            #DEBUGHACK - END

            if self.visual and best_fit_positions[dim] is not None:

                Y = np.ones(len(best_fit_positions[dim])) * 50
                Y2 = np.ones(positions[dim].shape) * 100
                plt.clf()

                if self.dim_order[dim] == 1:

                    plt.imshow(im[:, 900: 1200].T, cmap=plt.cm.gray)

                else:

                    plt.imshow(im[300: 600, :], cmap=plt.cm.gray)

                plt.plot(positions[dim], Y2, 'r*',
                    label='Detected spikes', lw=3, markersize=10)

                plt.plot(np.array(best_fit_positions[dim]),\
                    Y, 'g*', label='Selected positions', lw=3, markersize=10)

                plt.legend(loc=0)
                plt.ylim(ymin=0, ymax=150)
                plt.show()

            if best_fit_positions[dim] != None:

                #Comparing to previous
                if self.best_fit_positions != None:

                    if self.best_fit_positions[dim] != None:

                        R += ((best_fit_positions[dim] - \
                            self.best_fit_positions[dim]) ** 2).sum() / \
                            float(pinning_matrix[dim])

                        #Updating previous
                        self.logger.info(
                            "GRID ARRAY, Got a grid R at, {0}".format(R))

        if R < 20 and best_fit_positions[0] != None and \
                             best_fit_positions[1] != None:

            #self.best_fit_start_pos = best_fit_start_pos
            self.best_fit_frequency = best_fit_frequency
            self.best_fit_positions = best_fit_positions
            self.R = R

        else:

            self.R = -1

        if self.best_fit_positions == None:

            return None, None, None, adjusted_by_history

        else:

            ret_tuple = (self.best_fit_positions[0],
                    self.best_fit_positions[1], self.R,
                    adjusted_by_history)

            return ret_tuple
"""
FROM: analysis_grid_array.py
CLASS: Grid_Array
"""

    def get_analysis_old(self, im, gs_fit=None, gs_values=None, use_fallback=False,
                use_otsu=True, median_coeff=None, verbose=False, visual=False,
                watch_colony=None, suppress_analysis=False,
                save_grid_name=None, identifier_time=None,
                save_anime_name=None, timestamp=None, animate=False):

        """Returns analysis!
        @param im: An array / the image

        @param gs_fit : An array of the fitted coefficients for the grayscale

        @param gs_values : An array of the grayscale pixelvalues, if
        submittet gs_fit is disregarded

        @param use_otsu : Causes thresholding to be done by Otsu
        algorithm (Default)

        @param median_coeff : Coefficient to threshold from the
        median when not using Otsu.

        @param verbose : If a lot of things should be printed out

        @param visual : If visual information should be presented.

        @param save_grid_name : A custom name for the saved image, if none
        is submitted, it will be grid.png in current directory.

        @param identifier_time : A time index to update the identifier with

        @param save_anime_name : Path to where to save animation figure

        The function returns two arrays, one per dimension, of the
        positions of the spikes and a quality index
        """

        if identifier_time is not None:
            self._identifier[0] = identifier_time

        debug_per_plate = False

        #DEBUGHACK
        #visual = True
        #verbose = True
        #debug_per_plate = True
        #DEBUGHACK - END

        self.watch_source = None
        self.watch_scaled = None
        self.watch_blob = None
        self.watch_results = None

        if debug_per_plate:

            raw_input("Waiting to start next plate (press Enter)")

        if self._best_fit_columns is None:

            if not self.set_grid(im, save_grid_name=save_grid_name,
                    use_otsu=use_otsu, median_coeff=median_coeff,
                    verbose=verbose, visual=visual):

                self.logger.critical('Failed to set grid on ' + \
                        '{0} and none to use'.format(self._identifier))

                return None

        if (min(self._pinning_matrix) == self._pinning_matrix[1]) != \
            (min(im.shape) == im.shape[1]):

            ax1 = 0
            ax2 = 1
            s_bfc = self._best_fit_rows
            s_bfr = self._best_fit_columns
            s_gcs = [self._grid_cell_size[1], self._grid_cell_size[0]]

        else:

            ax1 = 1
            ax2 = 0
            s_bfr = self._best_fit_rows
            s_bfc = self._best_fit_columns
            s_gcs = self._grid_cell_size

        #total_steps = float(self._pinning_matrix[0] * self._pinning_matrix[1])

        #DEBUG PLOT GRID
        #debug_fig = plt.figure()
        #debug_ax = debug_fig.add_subplot(1,1,1)
        #debug_ax.imshow(im)
        #if self._best_fit_rows is not None:
            #debug_cols = (0, im.shape[0])
            #for debug_row in self._best_fit_rows:
                #debug_ax.plot((debug_row, debug_row),debug_cols,'k')
        #if self._best_fit_columns is not None:
            #debug_rows = (0, im.shape[1])
            #for debug_col in self._best_fit_columns:
                #debug_ax.plot(debug_rows,(debug_col,debug_col),'k')
        #debug_fig.show()
        #self.logger.warning("Pining (R,C) " + \
            #"{0} best_rows {1} best_cols {2}".format(
            #self._pinning_matrix, self._best_fit_rows, best_fit_columns))
        #raw_input("> ")
        #DEBUG PLOT GRID END

        #Normalising towards grayscale before anything is done on the colonies
        transformation_matrix = None
        

        #KODAK neutral scale
        if self._parent is not None:

            gs_indices = self._parent.gs_indices

        else:

            gs_indices = None

        if gs_values == None:

            transformation_matrix = self.get_transformation_matrix(\
                gs_fit=gs_fit, gs_indices=gs_indices)

        else:

            transformation_matrix = self.get_transformation_matrix(\
                gs_values=gs_values, gs_indices=gs_indices)

        #print "\n***Transformation matrix"
        #print transformation_matrix

        #if watch_colony != None:
        #    ul = self._grid_cells[watch_colony[1]][watch_colony[2]]\
                #.get_top_left()
        #    lr = self._grid_cells[watch_colony[1]][watch_colony[2]]\
                #.get_bottom_right()
        #    self.watch_source = im[ul[1]:lr[1],ul[0]:lr[0]]

        #if transformation_matrix != None:
            #There's probably some faster way
            #for x in xrange(im.shape[0]):
                #for y in xrange(im.shape[1]):
                    #im[x,y] = transformation_matrix[im[x,y]]
        #print "*** Analysing grid:"

        tf_im = np.zeros(s_gcs, dtype=np.float64)

        for row in xrange(self._pinning_matrix[ax1]):

            for column in xrange(self._pinning_matrix[ax2]):

                if suppress_analysis == False or (watch_colony != None and \
                        watch_colony[1] == row and watch_colony[2] == column):

                    _cur_gc = self._grid_cells[row][column]

                    row_min = s_bfr[row]
                    col_min = s_bfc[column]

                    _cur_gc.set_center(
                                    (row_min,
                                    col_min),
                                    s_gcs)

                    if transformation_matrix is not None:

                        #There's probably some faster way
                        self.logger.debug(
                                "ANALYSIS GRID ARRAY Transforming -> Kodak")

                        for x in xrange(tf_im.shape[ax1]):

                            x2 = int(round(row_min)) + x
                                        #- s_gcs[0] / 2.0)) + x

                            for y in xrange(tf_im.shape[ax2]):

                                y2 = int(round(col_min)) + y
                                        #- s_gcs[1] / 2.0)) + y

                                try:
                                    tf_im[x, y] = \
                                        transformation_matrix[im[x2, y2]]

                                except IndexError:

                                    self.logger.critical(\
                                        "Index Error:An image has been " + \
                                        " saved as gridding_error.png\n" + \
                                        "tf_im.shape {0} vs ({1}, {2})".format(
                                        tf_im.shape, x, y) + \
                                        "and im.shape {0} vs ".format(im.shape
                                        ) + "({0}, {1})\nbest_fit ".format(
                                        x2, y2) + \
                                        "({0}, {1}) size ({2}, {3}) ".format(
                                        col_min,
                                        row_min,
                                        s_gcs[ax1],
                                        s_gcs[ax2]) + \
                                        "from {0}:{1}:{2}".format(
                                        self._identifier, (row, 
                                        self._pinning_matrix[ax1]), (column,
                                        self._pinning_matrix[ax2])))

                                    grid_image = plt.figure()
                                    grid_plot = grid_image.add_subplot(111)
                                    grid_plot.imshow(im, cmap=plt.cm.Greys)
                                    grid_plot.set_xlim(0, im.shape[ax1-1])
                                    grid_plot.set_ylim(0, im.shape[ax2-1])

                                    for row in xrange(self._pinning_matrix[ax1]):

                                        grid_plot.plot(
                                            np.ones(
                                            len(s_bfc)) * \
                                            s_bfr[row],
                                            np.array(s_bfc),
                                            'r-')

                                        for column in xrange(
                                                self._pinning_matrix[ax2]):

                                            grid_plot.plot(
                                                np.array(s_bfr),
                                                np.ones(
                                                len(s_bfr)) * \
                                                s_bfc[column],
                                                'r-')

                                    grid_plot.add_patch(plt.Rectangle((y2,x2),
                                        tf_im.shape[ax1-1],
                                        tf_im.shape[ax2-1],
                                        ls='solid', lw=2,
                                        fill=False, ec=(0.9, 0.9, .1, 1)))

                                    grid_image.savefig("gridding_error.png")

                                    err_str = "Image showing the grid that " +\
                                                "caused it: gridding_error.png"

                                    raise Exception(IndexError, err_str)

                                    sys.exit()

                    else:

                        self.logger.critical("ANALYSIS GRID ARRAY Lacks" + \
                                " transformation possibilities")

                    _cur_gc.set_data_source(tf_im)

                    #if watch_colony != None:
                        #if row == watch_colony[1] and column \
                                    #== watch_colony[2]:

                            #self.watch_scaled = tf_im
                            #if self.watch_scaled.sum() == \
                                    #(self.watch_scaled > 0).sum():

                                ###DEBUG WHAT IS THE GRID ARRAY
                                #plt.clf()
                                #plt.imshow(self.watch_scaled, title='Grid')
                                #plt.show()
                                ###END DEBUG CODE

                    #This happens only the first time
                    if self._first_analysis:

                        _cur_gc.attach_analysis(
                                blob=True, background=True, cell=True,
                                use_fallback_detection=use_fallback,
                                run_detect=False)


                    #Gather info on the blob
                    self._features[row][col] = _cur_gc.get_analysis()

                    if watch_colony is not None \
                                and row == watch_colony[1] \
                                and column == watch_colony[2]:

                        blob = _cur_gc.get_item('blob')

                        background = _cur_gc.get_item('background')

                        if animate:
                            #plt.clf()
                            fig = plt.figure()
                            #gs = gridspec.GridSpec(2, 2)
                            #ax = fig.add_subplot(221, title="Blob")
                            #fig.gca().imshow(blob.filter_array)
                            #ax = fig.add_subplot(222, title ="Background")
                            #fig.gca().imshow(_cur_gc.get_item('background')\
                                #.filter_array)

                            #DEBUG CODE START
                            #blob = _cur_gc.get_item('blob')
                            #plt.clf()
                            #plt.subplot(211, title='filter all done')
                            #plt.imshow(blob.filter_array)
                            #plt.subplot(212, title='image')
                            #plt.imshow(blob.grid_array, vmax=3500, vmin=0)
                            #plt.show()
                            #DEBUG CODE END

                            ax = fig.add_subplot(221, title="Image t={0}".\
                                    format(self._identifier[0]))

                            ax_im = fig.gca().imshow(blob.grid_array, vmin=0,
                                    vmax=3500)

                            ax.get_xaxis().set_visible(False)
                            ax.get_yaxis().set_visible(False)
                            #fig.colorbar(ax_im,ax)

                            ax = fig.add_subplot(223, title="Blob")
                            ax_im = fig.gca().imshow(blob.filter_array)
                            ax.get_xaxis().set_visible(False)
                            ax.get_yaxis().set_visible(False)

                            ax = fig.add_subplot(224, title="Background")
                            ax_im = fig.gca().imshow(background.filter_array)
                            ax.get_xaxis().set_visible(False)
                            ax.get_yaxis().set_visible(False)

                        if self._old_blob_img is not None and \
                                    self._old_timestamp is not None:

                            blob_diff = blob.get_diff(self._old_blob_img,
                                self._old_blob_filter)

                            #onion2 = blob.get_onion_values(blob_diff,
                                #self._old_blob_filter,
                                #2)
                            #onion2t = blob.get_onion_values(blob_diff,
                                #blob.filter_array,
                                #2)
                            #onion4 = blob.get_onion_values(blob_diff,
                                #self._old_blob_filter,
                                #4)

                            onion6 = blob.get_onion_values(blob_diff,
                                            self._old_blob_filter,
                                            6)

                            self._onion_store.insert(0,
                                    ((onion6[-1, 0] / onion6[-1, 1]) / \
                                    ((self._old_timestamp - timestamp) / \
                                    (3600.0))))

                            self._onion_times.insert(0, (timestamp + \
                                    (self._old_timestamp - timestamp) / 2.0) /\
                                    (3600.0))

                                #onion2t[-1,0]/float(onion2t[-1,1])))
                                #onion4[-1,0]/float(onion4[-1,1]),
                                #onion6[-1,0]/float(onion6[-1,1])))

                            #fig3 = plt.figure()
                            #fig3.add_subplot(2,2,1, title = 'now')
                            #fig3.gca().imshow(blob.grid_array, vmin=0,
                                    #vmax=3500)
                            #fig3.add_subplot(2,2,2, title = 'previous')
                            #fig3.gca().imshow(self._old_blob_img, vmin=0,
                                    #vmax=3500)
                            #fig3.add_subplot(2,2,3, title = 'previous')
                            #fig3.gca().imshow(im, vmin=0, vmax=3500)
                                #uncertain of if everything is cool here
                            #fig3.gca().plot([y2 - self._grid_cell_size[0]/2],
                                #[x2[0] - self._grid_cell_size[1]/2], 'ro')
                            #fig3.show()
                            #raw_input("now max {0} vs old {1}> ".format(
                                    #blob.grid_array.max(),
                                    #self._old_blob_img.max()))

                            if self._identifier[0] == 0:

                                onion_times = np.asarray(self._onion_times)
                                onion_store = np.asarray(self._onion_store)
                                onion_labels = ['T2 outer using true dt',
                                    'T2 outer using equal dt']
                                    #'Thickness 4, outer',
                                    #'Thickness 6, outer']

                                np.save('onion_start_val', np.array(
                                        (np.log2(onion6[-1, 0]),)))
                                np.save('onion_store_arr', onion_store)
                                np.save('onion_times_arr', onion_times)

                                #fig2 = plt.figure()
                                #fig2.gca().set_title("1st Derivative of "
                                   #"Outer Onion Peels (t vs t+1 onionrings")

                                #for i in xrange(onion_store.shape[0]):

                                    #fig2.gca().plot(
                                        #np.arange(onion_store.size),
                                        #np.arange(onion_store.shape[0]),
                                        #onion_store, '-',
                                        #label=onion_labels[0])

                                #fig2.gca().set_xlabel("Time indices")
                                #fig2.gca().set_ylabel("Avg cell estimate" +
                                    #" diff to next time-pt")
                                #fig2.gca().legend(loc=0)
                                #fig2.savefig("onion.png")

                            if animate:

                                ax = fig.add_subplot(222,
                                        title="Delta Cells Image")

                                ax_im = fig.gca().imshow(blob_diff,
                                        vmin=-700, vmax=700,
                                        cmap=plt.cm.RdYlGn)

                                ax.get_xaxis().set_visible(False)
                                ax.get_yaxis().set_visible(False)
                                fig.colorbar(ax_im)  # fraction=2)

                                #ax = fig.add_subplot(224,
                                        #title="Onion Avg Residuals")
                                #ax_im = fig.gca().plot(
                                        #np.arange(onion6.shape[0]),
                                        #onion6[:,0]/onion6[:,1]\
                                        #.astype(np.float64),
                                        #'g-')
                                #ax.set_xlabel(
                                    #'Onion layer index (0 = center of blob)')
                                #ax.set_ylabel('Avg residual(t+1 - t')
                                #ax.set_autoscalex_on(False)
                                #ax.set_autoscaley_on(False)
                                #ax.set_ylim((-150,300))
                                #ax.set_xlim((0,5))

                        else:

                            self._onion_times = []
                            self._onion_store = []

                        self._old_blob_img = blob.grid_array.copy()
                        self._old_blob_filter = blob.filter_array.copy()

                        if animate:
                            #ax = fig.add_subplot(313, title = "Growth-curve")
                            #fig.gca().semilogy(self.track_times,
                                #self.track_values,
                                #'b-', basey=2)
                            #self.track_times.append(self._identifier[0])
                            #self.track_values.append(
                                #self._features[row][column]\
                                #['blob']['pixelsum'])
                            #fig.gca().semilogy((self.track_times[-1],), (
                                #self.track_values[-1],),'ro', basey=2)
                            #ax.set_yticklabels(("0","2^5","1^6"))
                            #ax.set_yscale('log', basey=2)
                            #ax.set_yticks((0,5,6))
                            #plt.xlim(0, self.track_times[0])
                            #plt.ylim(0, max(self.track_values))
                            fig.savefig(save_anime_name)
                            del fig

                    if watch_colony != None:
                        if row == watch_colony[1] and \
                                    column == watch_colony[2]:

                            self.watch_blob = \
                                _cur_gc.get_item('blob').filter_array.copy()

                            self.watch_scaled = \
                                _cur_gc.get_item('blob').grid_array.copy()

                            self.watch_results = self._features[row][column]

        self._old_timestamp = timestamp

        #print str(((row+1)*self._pinning_matrix[1]+column+1)/total_steps)+"%"
        self._first_analysis = False

        return self._features
"""
FROM: analysis.py
CLASS: Grid_Image
DEF: get_analsys
"""

        if save_graph_image:

            for ga_i, grid_array in enumerate(self._grid_arrays):

                im = self.get_im_section(features[ga_i], scale_factor)

                cur_graph_name = save_graph_name + str(ga_i) + ".png"

                if grid_lock == False or grid_array._best_fit_rows is None:

                    grid_array.set_grid(im,
                        save_grid_name=(save_graph_image is None and
                        cur_graph_name or None),
                        use_otsu=use_otsu, median_coeff=None,
                        verbose=False, visual=False, dont_save_grid=False)

"""
FROM: analysis_grid_cell.py
CLASS: Grid_Cell
"""


    def set_rect_size(self, rect_size=None):

        if rect_size == None:
            rect_size = self.data_source.shape

        if self.center.all(-1):
            self.center = np.array(map(lambda x: x / 2.0, rect_size))

        self.rect = compute_rect(self.center, rect_size)

    def set_center(self, center, rect_size=None):

        # Set the new center:
        self.center = np.asarray(center)

        # find the rectSize:
        if rect_size is None:

            rect_size = self.get_rect_size()

        # Set rectSize, which also corrects for the new center:
        self.set_rect_size(rect_size)

    def set_offset(self, offset_vec):

        vec = np.asarray(offset_vec)
        vec.shape = self.center.shape
        self.center += vec
        self.set_center(self.center)

    def get_first_dim_as_tuple(self):

        return (self.rect[0], self.rect[0] + self.get_width())

    def get_second_dim_as_tuple(self):

        return (self.rect[1], self.rect[1] + self.get_height())

    def get_rect_size(self):

        return self.rect[2: 4]

    def get_rect(self):

        return self.rect

    def get_top_left(self):

        return self.rect[0: 2]

    def get_bottom_right(self):

        widthHeight = np.maximum(self.rect[2: 4] - 1, 0)

        return self.rect[0: 2] + widthHeight

    def get_bottom_left(self):

        x = self.rect[0]
        height = max(self.rect[3] - 1, 0)
        y = self.rect[1] + height

        return np.array([x, y])

    def get_top_right(self):

        width = np.max(self.rect[2] - 1)
        x = self.rect[0] + width
        y = self.rect[1]

        return np.array([x, y])

    def get_width(self):

        return self.rect[2]

    def get_height(self):

        return self.rect[3]

    def get_center(self):

        return self.center


"""
FROM: analysis_grid_cell_disection.py 
CLASS: Background 
DEF: detect
"""

            #kernel = get_round_kernel(radius=9)

            #self.filter_array = binary_erosion(self.filter_array,
            #                    structure=kernel, border_value=1)

            ###DEBUG CODE
            #print "Bg area", np.sum(self.filter_array),
            #print "of which shared with blob",
            #print np.sum(self.filter_array * self.blob.filter_array)
            #print "I am", self._identifier
            #if True:
            #if self._identifier[0][0] == 0 or self._identifier[0][0] % \
                #round(self._identifier[0][0]**0.5) == 0 or \
                #abs(self._identifier[0][0] - 189) < 3:

                #from matplotlib import pyplot as plt
                #plt.clf()
                #fig = plt.figure()
                #ax = fig.add_subplot(221, title="Blob")
                #fig.gca().imshow(self.blob.filter_array)
                #ax = fig.add_subplot(222, title ="Background")
                #fig.gca().imshow(self.filter_array)
                #ax = fig.add_subplot(223, title = "Image")
                #ax_im = fig.gca().imshow(self.grid_array, vmin=0, vmax=100)
                #fig.colorbar(ax_im)
                #fig.savefig("debug_cell_t" +\
                    # ("%03d" % self._identifier[0][0]))
            ###END DEBUG CODE

            #if remember_filter:

            #    self.old_filter = self.filter_array.copy()

"""
FROM: resource_calibration.py
CLASS: N/A
"""

#if filter_2 != "":
    #data_2 = np.asarray(data_list_2)
#
    ##GRAPH 1
    #plt.plot(data_1[data_1_joint_positions,1],data_2[data_2_joint_positions,1],'b.')
#
    #z1 = np.polyfit(data_1[data_1_joint_positions,1],data_2[data_2_joint_positions,1],1)
    #p1 = np.poly1d(z1)
    #xp = np.linspace(data_1[data_1_joint_positions,1].min(), data_1[data_1_joint_positions,1].max(), 100)
#
    #plt.plot(xp, p1(xp), 'g-', label='1nd deg')
    #plt.text(500, 1000, str(p1) + ", r: " + str(p1.r[0]))
#
    #plt.xlabel(filter_1)
    #plt.ylabel(filter_2)
    #plt.title("Comparison of independent measures")
    #plt.legend(loc=1)
    #plt.show()


#GRAPH 2
#z1 = np.polyfit(data_1[:,0], data_1[:,1],1)
#p1 = np.poly1d(z1)

#z2 = np.polyfit(data_1[:,0], data_1[:,1],2)
#p2 = np.poly1d(z2)

#z3 = np.polyfit(data_1[:,0], data_1[:,1],3)
#p3 = np.poly1d(z3)

#xp = np.linspace(data_1[:,0].min(), data_1[:,0].max(), 100)
#x_span = data_1[:,0].max() - data_1[:,0].max()
#y_span = data_1[:,1].max() - data_1[:,1].max()

plt.clf()
plt.plot(data_1[:,0], data_1[:,1], 'b.')
plt.plot(xp, p1(xp),'m-', label='1nd deg')
plt.plot(xp, p2(xp),'r-', label='2nd deg')
plt.plot(xp, p3(xp),'g-', label='3rd deg')
plt.xlabel("Mean Pixel-Darkening from Colony Growth in 'Kodak Space' (Larger negative number, more stuff on agar)")
plt.ylabel("Independet Cell Estimate per pixel")
plt.title(filter_1 + " based conversion to 'Cell Estimate Space'")
plt.legend(loc=0)
#plt.xlim(xmin=data_1[:,0].min() - x_span * 0.15, xmax=data_1[:,0].max() + x_span * 0.15)
#plt.ylim(ymin=data_1[:,1].min() - y_span * 0.15, ymax=data_1[:,1].max() + y_span * 0.15)
#plt.ylim(ymax=2100, ymin=-50)
#plt.xlim(xmax=5, xmin=-100)
plt.ylim(ymax=500, ymin=-50)
plt.xlim(xmax=5, xmin=-30)
plt.show()


if filter_2 != "":
    #GRAPH 3
    z1 = np.polyfit(data_2[:,0], data_2[:,1],1)
    p1 = np.poly1d(z1)

    z2 = np.polyfit(data_2[:,0], data_2[:,1],2)
    p2 = np.poly1d(z2)

    z3 = np.polyfit(data_2[:,0], data_2[:,1],3)
    p3 = np.poly1d(z3)

    xp = np.linspace(data_2[:,0].min(), data_2[:,0].max(), 100)
    x_span = data_2[:,0].max() - data_2[:,0].max()
    y_span = data_2[:,1].max() - data_2[:,1].max()

    plt.clf()
    plt.plot(data_2[:,0], data_2[:,1], 'b.')
    plt.plot(xp, p1(xp),'m-', label='1nd deg')
    plt.plot(xp, p2(xp),'r-', label='2nd deg')
    plt.plot(xp, p3(xp),'g-', label='3rd deg')
    plt.xlabel("Mean Pixel-Darkening from Colony Growth in 'Kodak Space' (Larger negative number, more stuff on agar)")
    plt.ylabel("Independet Cell Estimate per pixel")
    plt.title(filter_2 + " based conversion to 'Cell Estimate Space'")
    plt.legend(loc=0)
    #plt.xlim(xmin=data_1[:,0].min() - x_span * 0.15, xmax=data_1[:,0].max() + x_span * 0.15)
    #plt.ylim(ymin=data_1[:,1].min() - y_span * 0.15, ymax=data_1[:,1].max() + y_span * 0.15)
    plt.ylim(ymax=2100, ymin=-50)
    plt.xlim(xmax=5, xmin=-100)
    #plt.ylim(ymax=500, ymin=-50)
    #plt.xlim(xmax=5, xmin=-30)
    plt.show()
#GRAPH 2
#print data_1[:,1]
#data_1[:,1] = np.log(np.log(data_1[:,1]))
#print data_1[:,1]

#z1 = curve_fit(np.log,data_1[:,0], data_1[:,1])
#p1 = np.poly1d(z1)

#z2 = np.polyfit(data_1[:,0], data_1[:,1],2)
#p2 = np.poly1d(z2)

#z3 = np.polyfit(data_1[:,0], data_1[:,1],3)
#p3 = np.poly1d(z3)

#xp = np.linspace(data_1[:,0].min(), data_1[:,0].max(), 100)
#x_span = data_1[:,0].max() - data_1[:,0].max()
#y_span = data_1[:,1].max() - data_1[:,1].max()

#plt.clf()
#plt.plot(data_1[:,0], data_1[:,1], 'b.')
#plt.plot(xp, p1(xp),'m-', label='1nd deg')
#plt.plot(xp, p2(xp),'r-', label='2nd deg')
#plt.plot(xp, p3(xp),'g-', label='3rd deg')
#plt.xlabel("Mean Pixel-Darkening from Colony Growth in 'Kodak Space' (Larger negative number, more stuff on agar)")
#plt.ylabel("Log Independet Cell Estimate per pixel")
#plt.title(filter_1 + " based conversion to a logged 'Cell Estimate Space'")
#plt.legend(loc=0)
#plt.xlim(xmin=data_1[:,0].min() - x_span * 0.15, xmax=data_1[:,0].max() + x_span * 0.15)
#plt.ylim(ymin=data_1[:,1].min() - y_span * 0.15, ymax=data_1[:,1].max() + y_span * 0.15)
#plt.ylim(ymax=2100, ymin=-50)
#plt.xlim(xmax=5, xmin=-100)
#plt.show()

"""
FROM: analysis_grid_array_dissection.py
CLASS: Grid_Analysis
"""


    def get_analysis(self, im, pinning_matrix, use_otsu=True,
        median_coeff=None, verbose=False,
        visual=False, history=[], manual_threshold=None):
        """
        get_analysis is a convenience function for get_spikes and
        get_signal_position_and_frequency functions run on both
        dimensions of the image.

        (This function sets the self.im for get_spikes.)

        The function takes the following arguments:

        @im         An array / the image

        @pinning_matrix  A list/tuple/array where first position is
                        the number of rows to be detected and second
                        is the number of columns to be detected.

        @use_otsu   Causes thresholding to be done by Otsu
                    algorithm (Default)

        @median_coeff       Coefficient to threshold from the
                            median when not using Otsu.

        @verbose   If a lot of things should be printed out

        @visual     If visual information should be presented.

        @history    A history of the top-left positions selected
                    for the particular format for the particular plate

        The function returns two arrays, one per dimension, of the
        positions of the spikes and a quality index
        """

        self.im = im
        positions = [None, None]
        measures = [None, None]
        #best_fit_start_pos = [None, None]
        best_fit_frequency = [None, None]
        best_fit_positions = [None, None]
        adjusted_by_history = False
        R = 0
        if history is not None and len(history) > 0:

            history_rc = (np.array([h[1][0] for h in history]).mean(),
                np.array([h[1][1] for h in history]).mean())

            history_f = (np.array([h[2][0] for h in history]).mean(),
                np.array([h[2][1] for h in history]).mean())

        else:

            history_rc = None
            history_f = None

        #Obtaining current values
        for dimension in xrange(2):
            if median_coeff:

                positions[dimension], measures[dimension] = self.get_spikes(
                    dimension, im, visual, verbose, use_otsu, median_coeff,
                    manual_threshold=manual_threshold)

            else:

                positions[dimension], measures[dimension] = self.get_spikes(
                    dimension, im, visual, verbose, use_otsu,
                    manual_threshold=manual_threshold)

            #DEBUG ROBUSTNESS TEST
            #from random import randint
            #print "Positions before test:", len(positions[dimension])
            #pos_range = range(len(positions[dimension]))
            #for del_count in xrange(randint(1,5)+1):
                #del_pos = randint(0,len(pos_range)-1)
                #del pos_range[del_pos]
            #positions[dimension] = positions[dimension][pos_range]
            #measures[dimension] = measures[dimension][pos_range]
            #print "Deleted", del_count, "positions"
            #DEBUG END

            self.logger.info(
                "GRID ARRAY, Peak positions %sth dimension:\n%s" %\
                (str(dimension), str(positions[dimension])))

            best_fit_frequency[dimension] = r_signal.get_signal_frequency(\
                positions[dimension])

            if best_fit_frequency[dimension] is not None \
                                and history_f is not None:

                if abs(best_fit_frequency[dimension] /\
                            float(history_f[dimension]) - 1) > 0.1:

                    self.logger.warning(
                            ('GRID ARRAY, frequency abnormality for ' +\
                            'dimension {0} (Current {1}, Expected {2}'.format(
                            dimension, best_fit_frequency[dimension],
                            history_f)))

                    adjusted_by_history = True
                    best_fit_frequency[dimension] = history_f[dimension]

            best_fit_positions[dimension] = r_signal.get_true_signal(
                im.shape[int(dimension==0)], pinning_matrix[dimension],
                positions[dimension],
                frequency=best_fit_frequency[dimension],
                offset_buffer_fraction=0.5)

            if best_fit_positions[dimension] is not None and \
                                        history_rc is not None:

                goodness_of_signal = r_signal.get_position_of_spike(
                    best_fit_positions[dimension][0], history_rc[dimension],
                    history_f[dimension])

                if abs(goodness_of_signal) > 0.2:

                    self.logger.warning(("GRID ARRAY, dubious pinning " + \
                        "position for  dimension {0} (Current signal " + \
                        "start {1}, Expected {2} (error: {3}).".format(
                        dimension, best_fit_positions[dimension][0],
                        history_rc[dimension], goodness_of_signal)))

                    adjusted_by_history = True

                    new_fit = r_signal.move_signal(
                        [best_fit_positions[dimension]],
                        [-1 * round(goodness_of_signal)], freq_offset=0)

                    if new_fit is not None:

                        self.logger.warning(
                            "GRID ARRAY, remapped signal for " +\
                            "dimension {0} , new signal:\n{1}".format(
                            dimension, list(new_fit)))

                        best_fit_positions[dimension] = new_fit[0]

            ###START HERE MARKING OUT ALL OLD STUFF...
            #best_fit_start_pos[dimension], best_fit_frequency[dimension] = \
                #self.get_signal_position_and_frequency( measures[dimension],
                    #pinning_matrix[dimension], verbose)

            self.logger.info("GRID ARRAY, Best fit:\n" +\
                "* Elements: " + str(pinning_matrix[dimension]) +\
                "\n* Positions:\n" + str(best_fit_positions[dimension]))

            #DEBUGHACK
            #visual = True
            #DEBUGHACK - END

            if visual:
                Y = np.ones(pinning_matrix[dimension]) * 50
                Y2 = np.ones(positions[dimension].shape) * 100
                plt.clf()
                if dimension == 1:
                    plt.imshow(im[:,900:1200].T, cmap=plt.cm.gray)
                else:
                    plt.imshow(im[300:600,:], cmap=plt.cm.gray)

                plt.plot(positions[dimension], Y2, 'r*',
                    label='Detected spikes', lw=3, markersize=10)

                plt.plot(np.array(best_fit_positions[dimension]),\
                    Y ,'g*', label='Selected positions', lw=3, markersize=10)

                plt.legend(loc=0)
                plt.ylim(ymin=0, ymax=150)
                plt.show()
                #plt.savefig('signal_fit.png')
                #DEBUG HACK
                #visual = False
                #DEBUG HACK
            #if best_fit_start_pos[dimension] != None:

                #best_fit_positions[dimension] = \
                    #positions[dimension][best_fit_start_pos[dimension] : \
                        #best_fit_start_pos[dimension] + \
                        #pinning_matrix[dimension] ]

                #if visual:

                    #import matplotlib.pyplot as plt
                    #m_im = im.mean(axis=dimension)
                    #plt.plot(np.arange(len(m_im)), m_im, 'b-')
                    #Y = np.ones(len(best_fit_positions[dimension])) * 150
                    #plt.plot(np.array(best_fit_positions[dimension]),\
                        #Y ,'r*')

                #best_fit_positions[dimension] = \
                    #self.get_inserts_discards_extrapolations(\
                        #best_fit_positions[dimension],\
                        #best_fit_frequency[dimension],\
                        #pinning_matrix[dimension])

                #if visual:
                    #Y = np.ones(len(positions[dimension])) * 140
                    #plt.plot(np.array(positions[dimension]),\
                        #Y ,'g*') * 50
                    #Y = np.ones(len(best_fit_positions[dimension])) * 160
                    #plt.plot(np.array(best_fit_positions[dimension]),\
                        #Y ,'b*')
                    #plt.get_axes().set_ylim(ymin=-1,ymax=3)
                    #plt.show()

            if best_fit_positions[dimension] != None:

                #Comparing to previous
                if self.best_fit_positions != None:
                    if self.best_fit_positions[dimension] != None:
                        R += ((best_fit_positions[dimension] - \
                            self.best_fit_positions[dimension])**2).sum() / \
                            float(pinning_matrix[dimension])



                        #Updating previous
                        self.logger.info(
                            "GRID ARRAY, Got a grid R at, {0}".format(R))

        #DEBUG R
        #fs = open('debug_R.log','a')
        #if self.best_fit_positions is None:
            #fs.write(str([best_fit_positions[0][0],
                    #best_fit_positions[1][0]]) + "\n")
        #else:
            #fs.write(str([R, (best_fit_positions[0][0],
                #best_fit_positions[1][0]),
                #(self.best_fit_positions[0][0],
                #self.best_fit_positions[1][0]) ]) + "\n")
        #fs.close()
        #DEBUG END

        if R < 20 and best_fit_positions[0] != None and \
                             best_fit_positions[1] != None:

            #self.best_fit_start_pos = best_fit_start_pos
            self.best_fit_frequency = best_fit_frequency
            self.best_fit_positions = best_fit_positions
            self.R = R

        else:

            self.R = -1

        if self.best_fit_positions == None:

            return None, None, None, adjusted_by_history

        else:

            ret_tuple = (self.best_fit_positions[0],
                    self.best_fit_positions[1], self.R,
                    adjusted_by_history)

            return ret_tuple


"""
FROM: analysis_grid_cell_disection.py
CLASS: Blob
"""


    def set_first_step_filtering(self):
        """Crashed this on my way to toronto, fix!" """

        #DEBUG CODE START
        #from matplotlib import pyplot as plt
        #plt.subplot(221, title='Start image')
        #plt.imshow(self.grid_array)
        #DEBUG CODE END

        #De-noising the image with a smooth
        detect_im = gaussian_filter(self.grid_array, 2)

        #detect_im = median_filter(self.grid_array, size=(3, 3),
        #                mode="nearest")

        #DEBUG CODE START
        #plt.subplot(222, title = 'Image after gauss')
        #plt.imshow(self.grid_array)
        #plt.subplot(223, title = 'Filter after gauss')
        #plt.imshow(self.filter_array)
        #DEBUG CODE END

        #Threshold the image
        self.threshold_detect(im=detect_im)

        #DEBUG CODE START
        #plt.subplot(224, title = 'Filter after threshold')
        #plt.imshow(self.filter_array)
        #plt.show()
        #DDEBUG CODE END

        #self.filter_array = sobel(self.grid_array)

        #print np.sum(self.filter_array), "pixels inside at this stage"
        #from scipy.ndimage.filters import sobel
        #from scipy.ndimage.morpholgy import binary_erosion, binary_dilation,
        #    binary_fill_holes, binary_closing

        #Not neccesary per se, but we need a copy anyways
        #mat = cv.fromarray(self.filter_array)
        #print "**Mat made"
        #eroded_mat = cv.CreateMat(mat.rows, mat.cols, cv.CV_8UC1)

        #Erosion kernel
        #kernel = get_round_kernel(radius=2)
        #print kernel.astype(int)
        #print "***Erosion kernel ready"

        self.filter_array = binary_erosion(self.filter_array,
                                    structure=self.kernel)

        #Erode, radius 6, iterations = default (1)
        #kernel = cv.CreateStructuringElementEx(radius*2+1, radius*2+1,
        #    radius, radius, cv.CV_SHAPE_ELLIPSE)

        #print "Kernel in place", kernel
        #cv.Erode(mat, eroded_mat, kernel)
        #print "Eroded"
        #print np.sum(self.filter_array), "pixels inside at this stage"
        #Dilate, radius 4, iterations = default (1)
        #radius = 4
        #kernel = cv.CreateStructuringElementEx(radius*2+1, radius*2+1,
        #    radius, radius, cv.CV_SHAPE_ELLIPSE)

        #kernel = get_round_kernel(radius=4)

        #print "Kernel in place"
        self.filter_array = binary_dilation(self.filter_array,
                                        structure=self.kernel)

        #cv.Dilate(mat, mat, kernel)
        #print "Dilated"
        #print np.sum(self.filter_array), "pixels inside at this stage"

        #self.filter_array = binary_closing(self.filter_array)
                                    #structure=kernel)

        #print "Closing applied"
        #print np.sum(self.filter_array), "pixels inside at this stage"

        #self.filter_array = sobel(self.filter_array)

        #print "Edged detected"
        #print np.sum(self.filter_array), "pixels inside at this stage"

        #self.filter_array = binary_fill_holes(self.filter_array,
                    #structure=np.ones((5, 5)))

        #print "Holes filled"
        #print np.sum(self.filter_array), "pixels inside at this stage"

    def edge_detect_sobel(self):
        """This is a scetch for another detect, and should Not
        bw used"""

        from matplotlib import pyplot

        #De-noising the image with a smooth
        self.filter_array = gaussian_filter(self.grid_array, 2)
        pyplot.imshow(self.filter_array)
        pyplot.savefig('blob_gauss.png')
        pyplot.clf()

        #Checking the second dirivative
        #self.filter_array = laplace(self.filter_array)
        self.filter_array = sobel(self.filter_array, 0) ** 2 + \
                            sobel(self.filter_array, 1) ** 2

        pyplot.imshow(self.filter_array)
        #pyplot.savefig('blob_laplace.png')
        pyplot.savefig('blob_sobel.png')
        pyplot.clf()

        #self.filter_array = gaussian_filter(self.filter_array, 2)
        #pyplot.imshow(self.filter_array)
        #pyplot.savefig('blob_gauss2.png')
        #pyplot.clf()

        #Thesholding the edges
        self.threshold_detect(im=self.filter_array, color_logic='norm',
            threshold=np.max(self.filter_array) * 0.2)

        pyplot.imshow(self.filter_array)
        pyplot.savefig('blob_theshold.png')
        pyplot.clf()

        kernel = get_round_kernel(radius=3)
        self.filter_array = binary_dilation(self.filter_array,
                                            structure=kernel)

        pyplot.imshow(self.filter_array)
        pyplot.savefig('blob_dilation.png')
        pyplot.clf()

        kernel = get_round_kernel(radius=2)
        self.filter_array = binary_erosion(self.filter_array, structure=kernel)

        pyplot.imshow(self.filter_array)
        pyplot.savefig('blob_erosion.png')
        pyplot.clf()

        label_array, number_of_labels = label(self.filter_array)
        #print number_of_labels
        kernel = get_round_kernel(radius=1)
        center_size = 2
        circle_parts = []

        for i in xrange(number_of_labels):

            cur_item = (label_array == (i + 1))
            cur_pxs = np.sum(cur_item)

            if cur_pxs > 100:
                #c_o_m = center_of_mass(cur_item)
                #print "Mass centra: ", c_o_m
                oneD = np.where(np.sum(cur_item, 1) > 0)[0]
                dim1 = (oneD[0], oneD[-1])
                oneD = np.where(np.sum(cur_item, 0) > 0)[0]
                dim2 = (oneD[0], oneD[-1])
                cur_off = 2
                good_part = True

                if cur_item[dim1[0]: dim1[1], dim2[0] + cur_off].sum() / \
                                float(cur_pxs)\
                                >= cur_pxs / float(dim2[1] - dim2[0]):

                    good_part = False

                if good_part and cur_item[dim1[0]: dim1[1],
                                dim2[1] - cur_off].sum() / float(cur_pxs)\
                                >= cur_pxs / float(dim2[1] - dim2[0]):

                    good_part = False

                if cur_item[dim2[0]: dim2[1], dim1[0] + cur_off].sum() / \
                                float(cur_pxs)\
                                >= cur_pxs / float(dim1[1] - dim1[0]):

                    good_part = False

                if good_part and cur_item[dim2[0]: dim2[1],
                                dim1[1] - cur_off].sum() / float(cur_pxs)\
                                >= cur_pxs / float(dim1[1] - dim1[0]):

                    good_part = False

                #if cur_item[c_o_m[0]-center_size:c_o_m[0]+center_size,
                #    c_o_m[1]-center_size: c_o_m[1]+center_size].sum() > 0:

                if good_part == False:

                    pyplot.imshow(binary_erosion((label_array == (i + 1)),
                                                        structure=kernel))

                    pyplot.savefig('blob_item_' + str(i + 1) + '_bad.png')
                    pyplot.clf()

                else:

                    pyplot.imshow(binary_erosion((label_array == (i + 1)),
                                                        structure=kernel))

                    pyplot.savefig('blob_item_' + str(i + 1) + '.png')
                    pyplot.clf()
                    circle_parts.append(i + 1)

        self.filter_array = np.zeros(self.filter_array.shape)

        for c_part in circle_parts:

            #print self.filter_array.shape, label_array.shape
            self.filter_array += (label_array == c_part)

