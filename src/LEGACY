"""
FROM: resource_calibration.py
CLASS: N/A
"""

#if filter_2 != "":
    #data_2 = np.asarray(data_list_2)
#
    ##GRAPH 1
    #plt.plot(data_1[data_1_joint_positions,1],data_2[data_2_joint_positions,1],'b.')
#
    #z1 = np.polyfit(data_1[data_1_joint_positions,1],data_2[data_2_joint_positions,1],1)
    #p1 = np.poly1d(z1)
    #xp = np.linspace(data_1[data_1_joint_positions,1].min(), data_1[data_1_joint_positions,1].max(), 100)
#
    #plt.plot(xp, p1(xp), 'g-', label='1nd deg')
    #plt.text(500, 1000, str(p1) + ", r: " + str(p1.r[0]))
#
    #plt.xlabel(filter_1)
    #plt.ylabel(filter_2)
    #plt.title("Comparison of independent measures")
    #plt.legend(loc=1)
    #plt.show()


#GRAPH 2
#z1 = np.polyfit(data_1[:,0], data_1[:,1],1)
#p1 = np.poly1d(z1)

#z2 = np.polyfit(data_1[:,0], data_1[:,1],2)
#p2 = np.poly1d(z2)

#z3 = np.polyfit(data_1[:,0], data_1[:,1],3)
#p3 = np.poly1d(z3)

#xp = np.linspace(data_1[:,0].min(), data_1[:,0].max(), 100)
#x_span = data_1[:,0].max() - data_1[:,0].max()
#y_span = data_1[:,1].max() - data_1[:,1].max()

plt.clf()
plt.plot(data_1[:,0], data_1[:,1], 'b.')
plt.plot(xp, p1(xp),'m-', label='1nd deg')
plt.plot(xp, p2(xp),'r-', label='2nd deg')
plt.plot(xp, p3(xp),'g-', label='3rd deg')
plt.xlabel("Mean Pixel-Darkening from Colony Growth in 'Kodak Space' (Larger negative number, more stuff on agar)")
plt.ylabel("Independet Cell Estimate per pixel")
plt.title(filter_1 + " based conversion to 'Cell Estimate Space'")
plt.legend(loc=0)
#plt.xlim(xmin=data_1[:,0].min() - x_span * 0.15, xmax=data_1[:,0].max() + x_span * 0.15)
#plt.ylim(ymin=data_1[:,1].min() - y_span * 0.15, ymax=data_1[:,1].max() + y_span * 0.15)
#plt.ylim(ymax=2100, ymin=-50)
#plt.xlim(xmax=5, xmin=-100)
plt.ylim(ymax=500, ymin=-50)
plt.xlim(xmax=5, xmin=-30)
plt.show()


if filter_2 != "":
    #GRAPH 3
    z1 = np.polyfit(data_2[:,0], data_2[:,1],1)
    p1 = np.poly1d(z1)

    z2 = np.polyfit(data_2[:,0], data_2[:,1],2)
    p2 = np.poly1d(z2)

    z3 = np.polyfit(data_2[:,0], data_2[:,1],3)
    p3 = np.poly1d(z3)

    xp = np.linspace(data_2[:,0].min(), data_2[:,0].max(), 100)
    x_span = data_2[:,0].max() - data_2[:,0].max()
    y_span = data_2[:,1].max() - data_2[:,1].max()

    plt.clf()
    plt.plot(data_2[:,0], data_2[:,1], 'b.')
    plt.plot(xp, p1(xp),'m-', label='1nd deg')
    plt.plot(xp, p2(xp),'r-', label='2nd deg')
    plt.plot(xp, p3(xp),'g-', label='3rd deg')
    plt.xlabel("Mean Pixel-Darkening from Colony Growth in 'Kodak Space' (Larger negative number, more stuff on agar)")
    plt.ylabel("Independet Cell Estimate per pixel")
    plt.title(filter_2 + " based conversion to 'Cell Estimate Space'")
    plt.legend(loc=0)
    #plt.xlim(xmin=data_1[:,0].min() - x_span * 0.15, xmax=data_1[:,0].max() + x_span * 0.15)
    #plt.ylim(ymin=data_1[:,1].min() - y_span * 0.15, ymax=data_1[:,1].max() + y_span * 0.15)
    plt.ylim(ymax=2100, ymin=-50)
    plt.xlim(xmax=5, xmin=-100)
    #plt.ylim(ymax=500, ymin=-50)
    #plt.xlim(xmax=5, xmin=-30)
    plt.show()
#GRAPH 2
#print data_1[:,1]
#data_1[:,1] = np.log(np.log(data_1[:,1]))
#print data_1[:,1]

#z1 = curve_fit(np.log,data_1[:,0], data_1[:,1])
#p1 = np.poly1d(z1)

#z2 = np.polyfit(data_1[:,0], data_1[:,1],2)
#p2 = np.poly1d(z2)

#z3 = np.polyfit(data_1[:,0], data_1[:,1],3)
#p3 = np.poly1d(z3)

#xp = np.linspace(data_1[:,0].min(), data_1[:,0].max(), 100)
#x_span = data_1[:,0].max() - data_1[:,0].max()
#y_span = data_1[:,1].max() - data_1[:,1].max()

#plt.clf()
#plt.plot(data_1[:,0], data_1[:,1], 'b.')
#plt.plot(xp, p1(xp),'m-', label='1nd deg')
#plt.plot(xp, p2(xp),'r-', label='2nd deg')
#plt.plot(xp, p3(xp),'g-', label='3rd deg')
#plt.xlabel("Mean Pixel-Darkening from Colony Growth in 'Kodak Space' (Larger negative number, more stuff on agar)")
#plt.ylabel("Log Independet Cell Estimate per pixel")
#plt.title(filter_1 + " based conversion to a logged 'Cell Estimate Space'")
#plt.legend(loc=0)
#plt.xlim(xmin=data_1[:,0].min() - x_span * 0.15, xmax=data_1[:,0].max() + x_span * 0.15)
#plt.ylim(ymin=data_1[:,1].min() - y_span * 0.15, ymax=data_1[:,1].max() + y_span * 0.15)
#plt.ylim(ymax=2100, ymin=-50)
#plt.xlim(xmax=5, xmin=-100)
#plt.show()

"""
FROM: analysis_grid_array_dissection.py
CLASS: Grid_Analysis
"""


    def get_analysis(self, im, pinning_matrix, use_otsu=True,
        median_coeff=None, verbose=False,
        visual=False, history=[], manual_threshold=None):
        """
        get_analysis is a convenience function for get_spikes and
        get_signal_position_and_frequency functions run on both
        dimensions of the image.

        (This function sets the self.im for get_spikes.)

        The function takes the following arguments:

        @im         An array / the image

        @pinning_matrix  A list/tuple/array where first position is
                        the number of rows to be detected and second
                        is the number of columns to be detected.

        @use_otsu   Causes thresholding to be done by Otsu
                    algorithm (Default)

        @median_coeff       Coefficient to threshold from the
                            median when not using Otsu.

        @verbose   If a lot of things should be printed out

        @visual     If visual information should be presented.

        @history    A history of the top-left positions selected
                    for the particular format for the particular plate

        The function returns two arrays, one per dimension, of the
        positions of the spikes and a quality index
        """

        self.im = im
        positions = [None, None]
        measures = [None, None]
        #best_fit_start_pos = [None, None]
        best_fit_frequency = [None, None]
        best_fit_positions = [None, None]
        adjusted_by_history = False
        R = 0
        if history is not None and len(history) > 0:

            history_rc = (np.array([h[1][0] for h in history]).mean(),
                np.array([h[1][1] for h in history]).mean())

            history_f = (np.array([h[2][0] for h in history]).mean(),
                np.array([h[2][1] for h in history]).mean())

        else:

            history_rc = None
            history_f = None

        #Obtaining current values
        for dimension in xrange(2):
            if median_coeff:

                positions[dimension], measures[dimension] = self.get_spikes(
                    dimension, im, visual, verbose, use_otsu, median_coeff,
                    manual_threshold=manual_threshold)

            else:

                positions[dimension], measures[dimension] = self.get_spikes(
                    dimension, im, visual, verbose, use_otsu,
                    manual_threshold=manual_threshold)

            #DEBUG ROBUSTNESS TEST
            #from random import randint
            #print "Positions before test:", len(positions[dimension])
            #pos_range = range(len(positions[dimension]))
            #for del_count in xrange(randint(1,5)+1):
                #del_pos = randint(0,len(pos_range)-1)
                #del pos_range[del_pos]
            #positions[dimension] = positions[dimension][pos_range]
            #measures[dimension] = measures[dimension][pos_range]
            #print "Deleted", del_count, "positions"
            #DEBUG END

            self.logger.info(
                "GRID ARRAY, Peak positions %sth dimension:\n%s" %\
                (str(dimension), str(positions[dimension])))

            best_fit_frequency[dimension] = r_signal.get_signal_frequency(\
                positions[dimension])

            if best_fit_frequency[dimension] is not None \
                                and history_f is not None:

                if abs(best_fit_frequency[dimension] /\
                            float(history_f[dimension]) - 1) > 0.1:

                    self.logger.warning(
                            ('GRID ARRAY, frequency abnormality for ' +\
                            'dimension {0} (Current {1}, Expected {2}'.format(
                            dimension, best_fit_frequency[dimension],
                            history_f)))

                    adjusted_by_history = True
                    best_fit_frequency[dimension] = history_f[dimension]

            best_fit_positions[dimension] = r_signal.get_true_signal(
                im.shape[int(dimension==0)], pinning_matrix[dimension],
                positions[dimension],
                frequency=best_fit_frequency[dimension],
                offset_buffer_fraction=0.5)

            if best_fit_positions[dimension] is not None and \
                                        history_rc is not None:

                goodness_of_signal = r_signal.get_position_of_spike(
                    best_fit_positions[dimension][0], history_rc[dimension],
                    history_f[dimension])

                if abs(goodness_of_signal) > 0.2:

                    self.logger.warning(("GRID ARRAY, dubious pinning " + \
                        "position for  dimension {0} (Current signal " + \
                        "start {1}, Expected {2} (error: {3}).".format(
                        dimension, best_fit_positions[dimension][0],
                        history_rc[dimension], goodness_of_signal)))

                    adjusted_by_history = True

                    new_fit = r_signal.move_signal(
                        [best_fit_positions[dimension]],
                        [-1 * round(goodness_of_signal)], freq_offset=0)

                    if new_fit is not None:

                        self.logger.warning(
                            "GRID ARRAY, remapped signal for " +\
                            "dimension {0} , new signal:\n{1}".format(
                            dimension, list(new_fit)))

                        best_fit_positions[dimension] = new_fit[0]

            ###START HERE MARKING OUT ALL OLD STUFF...
            #best_fit_start_pos[dimension], best_fit_frequency[dimension] = \
                #self.get_signal_position_and_frequency( measures[dimension],
                    #pinning_matrix[dimension], verbose)

            self.logger.info("GRID ARRAY, Best fit:\n" +\
                "* Elements: " + str(pinning_matrix[dimension]) +\
                "\n* Positions:\n" + str(best_fit_positions[dimension]))

            #DEBUGHACK
            #visual = True
            #DEBUGHACK - END

            if visual:
                Y = np.ones(pinning_matrix[dimension]) * 50
                Y2 = np.ones(positions[dimension].shape) * 100
                plt.clf()
                if dimension == 1:
                    plt.imshow(im[:,900:1200].T, cmap=plt.cm.gray)
                else:
                    plt.imshow(im[300:600,:], cmap=plt.cm.gray)

                plt.plot(positions[dimension], Y2, 'r*',
                    label='Detected spikes', lw=3, markersize=10)

                plt.plot(np.array(best_fit_positions[dimension]),\
                    Y ,'g*', label='Selected positions', lw=3, markersize=10)

                plt.legend(loc=0)
                plt.ylim(ymin=0, ymax=150)
                plt.show()
                #plt.savefig('signal_fit.png')
                #DEBUG HACK
                #visual = False
                #DEBUG HACK
            #if best_fit_start_pos[dimension] != None:

                #best_fit_positions[dimension] = \
                    #positions[dimension][best_fit_start_pos[dimension] : \
                        #best_fit_start_pos[dimension] + \
                        #pinning_matrix[dimension] ]

                #if visual:

                    #import matplotlib.pyplot as plt
                    #m_im = im.mean(axis=dimension)
                    #plt.plot(np.arange(len(m_im)), m_im, 'b-')
                    #Y = np.ones(len(best_fit_positions[dimension])) * 150
                    #plt.plot(np.array(best_fit_positions[dimension]),\
                        #Y ,'r*')

                #best_fit_positions[dimension] = \
                    #self.get_inserts_discards_extrapolations(\
                        #best_fit_positions[dimension],\
                        #best_fit_frequency[dimension],\
                        #pinning_matrix[dimension])

                #if visual:
                    #Y = np.ones(len(positions[dimension])) * 140
                    #plt.plot(np.array(positions[dimension]),\
                        #Y ,'g*') * 50
                    #Y = np.ones(len(best_fit_positions[dimension])) * 160
                    #plt.plot(np.array(best_fit_positions[dimension]),\
                        #Y ,'b*')
                    #plt.get_axes().set_ylim(ymin=-1,ymax=3)
                    #plt.show()

            if best_fit_positions[dimension] != None:

                #Comparing to previous
                if self.best_fit_positions != None:
                    if self.best_fit_positions[dimension] != None:
                        R += ((best_fit_positions[dimension] - \
                            self.best_fit_positions[dimension])**2).sum() / \
                            float(pinning_matrix[dimension])



                        #Updating previous
                        self.logger.info(
                            "GRID ARRAY, Got a grid R at, {0}".format(R))

        #DEBUG R
        #fs = open('debug_R.log','a')
        #if self.best_fit_positions is None:
            #fs.write(str([best_fit_positions[0][0],
                    #best_fit_positions[1][0]]) + "\n")
        #else:
            #fs.write(str([R, (best_fit_positions[0][0],
                #best_fit_positions[1][0]),
                #(self.best_fit_positions[0][0],
                #self.best_fit_positions[1][0]) ]) + "\n")
        #fs.close()
        #DEBUG END

        if R < 20 and best_fit_positions[0] != None and \
                             best_fit_positions[1] != None:

            #self.best_fit_start_pos = best_fit_start_pos
            self.best_fit_frequency = best_fit_frequency
            self.best_fit_positions = best_fit_positions
            self.R = R

        else:

            self.R = -1

        if self.best_fit_positions == None:

            return None, None, None, adjusted_by_history

        else:

            ret_tuple = (self.best_fit_positions[0],
                    self.best_fit_positions[1], self.R,
                    adjusted_by_history)

            return ret_tuple


"""
FROM: analysis_grid_cell_disection.py
CLASS: Blob
"""


    def set_first_step_filtering(self):
        """Crashed this on my way to toronto, fix!" """

        #DEBUG CODE START
        #from matplotlib import pyplot as plt
        #plt.subplot(221, title='Start image')
        #plt.imshow(self.grid_array)
        #DEBUG CODE END

        #De-noising the image with a smooth
        detect_im = gaussian_filter(self.grid_array, 2)

        #detect_im = median_filter(self.grid_array, size=(3, 3),
        #                mode="nearest")

        #DEBUG CODE START
        #plt.subplot(222, title = 'Image after gauss')
        #plt.imshow(self.grid_array)
        #plt.subplot(223, title = 'Filter after gauss')
        #plt.imshow(self.filter_array)
        #DEBUG CODE END

        #Threshold the image
        self.threshold_detect(im=detect_im)

        #DEBUG CODE START
        #plt.subplot(224, title = 'Filter after threshold')
        #plt.imshow(self.filter_array)
        #plt.show()
        #DDEBUG CODE END

        #self.filter_array = sobel(self.grid_array)

        #print np.sum(self.filter_array), "pixels inside at this stage"
        #from scipy.ndimage.filters import sobel
        #from scipy.ndimage.morpholgy import binary_erosion, binary_dilation,
        #    binary_fill_holes, binary_closing

        #Not neccesary per se, but we need a copy anyways
        #mat = cv.fromarray(self.filter_array)
        #print "**Mat made"
        #eroded_mat = cv.CreateMat(mat.rows, mat.cols, cv.CV_8UC1)

        #Erosion kernel
        #kernel = get_round_kernel(radius=2)
        #print kernel.astype(int)
        #print "***Erosion kernel ready"

        self.filter_array = binary_erosion(self.filter_array,
                                    structure=self.kernel)

        #Erode, radius 6, iterations = default (1)
        #kernel = cv.CreateStructuringElementEx(radius*2+1, radius*2+1,
        #    radius, radius, cv.CV_SHAPE_ELLIPSE)

        #print "Kernel in place", kernel
        #cv.Erode(mat, eroded_mat, kernel)
        #print "Eroded"
        #print np.sum(self.filter_array), "pixels inside at this stage"
        #Dilate, radius 4, iterations = default (1)
        #radius = 4
        #kernel = cv.CreateStructuringElementEx(radius*2+1, radius*2+1,
        #    radius, radius, cv.CV_SHAPE_ELLIPSE)

        #kernel = get_round_kernel(radius=4)

        #print "Kernel in place"
        self.filter_array = binary_dilation(self.filter_array,
                                        structure=self.kernel)

        #cv.Dilate(mat, mat, kernel)
        #print "Dilated"
        #print np.sum(self.filter_array), "pixels inside at this stage"

        #self.filter_array = binary_closing(self.filter_array)
                                    #structure=kernel)

        #print "Closing applied"
        #print np.sum(self.filter_array), "pixels inside at this stage"

        #self.filter_array = sobel(self.filter_array)

        #print "Edged detected"
        #print np.sum(self.filter_array), "pixels inside at this stage"

        #self.filter_array = binary_fill_holes(self.filter_array,
                    #structure=np.ones((5, 5)))

        #print "Holes filled"
        #print np.sum(self.filter_array), "pixels inside at this stage"

    def edge_detect_sobel(self):
        """This is a scetch for another detect, and should Not
        bw used"""

        from matplotlib import pyplot

        #De-noising the image with a smooth
        self.filter_array = gaussian_filter(self.grid_array, 2)
        pyplot.imshow(self.filter_array)
        pyplot.savefig('blob_gauss.png')
        pyplot.clf()

        #Checking the second dirivative
        #self.filter_array = laplace(self.filter_array)
        self.filter_array = sobel(self.filter_array, 0) ** 2 + \
                            sobel(self.filter_array, 1) ** 2

        pyplot.imshow(self.filter_array)
        #pyplot.savefig('blob_laplace.png')
        pyplot.savefig('blob_sobel.png')
        pyplot.clf()

        #self.filter_array = gaussian_filter(self.filter_array, 2)
        #pyplot.imshow(self.filter_array)
        #pyplot.savefig('blob_gauss2.png')
        #pyplot.clf()

        #Thesholding the edges
        self.threshold_detect(im=self.filter_array, color_logic='norm',
            threshold=np.max(self.filter_array) * 0.2)

        pyplot.imshow(self.filter_array)
        pyplot.savefig('blob_theshold.png')
        pyplot.clf()

        kernel = get_round_kernel(radius=3)
        self.filter_array = binary_dilation(self.filter_array,
                                            structure=kernel)

        pyplot.imshow(self.filter_array)
        pyplot.savefig('blob_dilation.png')
        pyplot.clf()

        kernel = get_round_kernel(radius=2)
        self.filter_array = binary_erosion(self.filter_array, structure=kernel)

        pyplot.imshow(self.filter_array)
        pyplot.savefig('blob_erosion.png')
        pyplot.clf()

        label_array, number_of_labels = label(self.filter_array)
        #print number_of_labels
        kernel = get_round_kernel(radius=1)
        center_size = 2
        circle_parts = []

        for i in xrange(number_of_labels):

            cur_item = (label_array == (i + 1))
            cur_pxs = np.sum(cur_item)

            if cur_pxs > 100:
                #c_o_m = center_of_mass(cur_item)
                #print "Mass centra: ", c_o_m
                oneD = np.where(np.sum(cur_item, 1) > 0)[0]
                dim1 = (oneD[0], oneD[-1])
                oneD = np.where(np.sum(cur_item, 0) > 0)[0]
                dim2 = (oneD[0], oneD[-1])
                cur_off = 2
                good_part = True

                if cur_item[dim1[0]: dim1[1], dim2[0] + cur_off].sum() / \
                                float(cur_pxs)\
                                >= cur_pxs / float(dim2[1] - dim2[0]):

                    good_part = False

                if good_part and cur_item[dim1[0]: dim1[1],
                                dim2[1] - cur_off].sum() / float(cur_pxs)\
                                >= cur_pxs / float(dim2[1] - dim2[0]):

                    good_part = False

                if cur_item[dim2[0]: dim2[1], dim1[0] + cur_off].sum() / \
                                float(cur_pxs)\
                                >= cur_pxs / float(dim1[1] - dim1[0]):

                    good_part = False

                if good_part and cur_item[dim2[0]: dim2[1],
                                dim1[1] - cur_off].sum() / float(cur_pxs)\
                                >= cur_pxs / float(dim1[1] - dim1[0]):

                    good_part = False

                #if cur_item[c_o_m[0]-center_size:c_o_m[0]+center_size,
                #    c_o_m[1]-center_size: c_o_m[1]+center_size].sum() > 0:

                if good_part == False:

                    pyplot.imshow(binary_erosion((label_array == (i + 1)),
                                                        structure=kernel))

                    pyplot.savefig('blob_item_' + str(i + 1) + '_bad.png')
                    pyplot.clf()

                else:

                    pyplot.imshow(binary_erosion((label_array == (i + 1)),
                                                        structure=kernel))

                    pyplot.savefig('blob_item_' + str(i + 1) + '.png')
                    pyplot.clf()
                    circle_parts.append(i + 1)

        self.filter_array = np.zeros(self.filter_array.shape)

        for c_part in circle_parts:

            #print self.filter_array.shape, label_array.shape
            self.filter_array += (label_array == c_part)

